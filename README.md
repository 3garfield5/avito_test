## Задача: Восстановление пропущенных пробелов в тексте с помощью NLP / DL / алгоритма.
Как решать?
  *  Классический метод NLP (n-gram language model)
  *  DL метод NLP (fine-tuning BERT)
В данном случае нам нужно найти точное, быстрое и легковесное решение. Поэтому я решил проверить две гипотезы:

  *  Решить задачу легковесным и простым способом, при котором нам не нужно много вычислительных мощностей (будем делать все на CPU), но при этом потеряем качество решения.
  *  Решить задачу более сложным способом, при котором нам нужно достаточно вычислительных мощностей, но при этом мы выиграем в качестве решения задачи.
Суть: Проверить, что будет лучше и логичнее для бизнеса. Возможно легковесное решение будет хорошо справляться с задачей и нам не нужно дообучать BERT, а может быть и наоборот, что мы потеряем эффективность и точность, из-за чего классический метод тут совсем не подойдет.

Обучение n-gram language model производилось на CPU в Google Colab

Обучение BERT производилось на T4 GPU в Google Colab
