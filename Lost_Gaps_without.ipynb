{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEmZdPhpQ7lp"
      },
      "source": [
        "##Задача: Восстановление пропущенных пробелов в тексте с помощью NLP / DL / алгоритма.\n",
        "#**Как решать?**\n",
        "\n",
        "\n",
        "\n",
        "1.   Классический метод NLP (n-gram language model)\n",
        "2.   DL метод NLP (fine-tuning BERT)\n",
        "\n",
        "В данном случае нам нужно найти точное, быстрое и легковесное решение. Поэтому я решил проверить две гипотезы:\n",
        "\n",
        "\n",
        "*   Решить задачу легковесным и простым способом, при котором нам не нужно много вычислительных мощностей (будем делать все на CPU), но при этом потеряем качество решения.\n",
        "*   Решить задачу более сложным способом, при котором нам нужно достаточно вычислительных мощностей, но при этом мы выиграем в качестве решения задачи.\n",
        "\n",
        "**Суть:**\n",
        "Проверить, что будет лучше и логичнее для бизнеса. Возможно легковесное решение будет хорошо справляться с задачей и нам не нужно дообучать BERT, а может быть и наоборот, что мы потеряем эффективность и точность, из-за чего классический метод тут совсем не подойдет.\n",
        "\n",
        "Обучение n-gram language model производилось на CPU в Google Colab\n",
        "\n",
        "Обучение BERT производилось на T4 GPU в Google Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cdR7jh5miZN4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import kagglehub\n",
        "import math\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoTokenizer\n",
        "import torch\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kDetPltUu5p"
      },
      "source": [
        "#N-gram model\n",
        "В данном случае мы будем реализовать модель, которая не будет генерировать последовательность токенов, а наоборот проверять, насколько вероятно, что то или иное разбиение строки на символы, является именно тем словом. А разбивать будет именно алогритм. То есть получаем решение: динамическое программирование + словарь + вероятностная модель (n-граммы, unigram). Для этого нам необходимо найти специфичный датасет, который поможет нам решить задачу. Поискав в интернете, я нашел датасет на каггле avito-dataset. Он идеально для нас подходит, потому что у нас есть названия разных объявлений и их описаний. Это дает нам преимущество в том, что сохраняется специфичность запросов.\n",
        "Подгружаем его"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d41eqGiaT99a",
        "outputId": "771d0279-2600-4526-dcfb-90df482f9fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'avito-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/avito-dataset\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download(\"vitaliy3000/avito-dataset\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Pj0k1UrSUe_c"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/kaggle/input/avito-dataset/train.csv') # если не запускается ячейка, то запустите прошлую ячейку еще раз"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQujnCcHU5SJ"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нам нужен список из названий объявлений и их описаний, поэтому создаем его"
      ],
      "metadata": {
        "id": "pUcd9fYkGaH6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jznW_L9VFZc"
      },
      "outputs": [],
      "source": [
        "lines = data.apply(lambda row: row['title'] + '. ' + row['description'], axis=1).tolist()\n",
        "lines"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Очищаем текст от служебных знаков, лишних смайликов и тд"
      ],
      "metadata": {
        "id": "OfzlZ7RWGi0T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yRT9kvOPpn_g"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s\\.\\,\\!\\?\\-\\:]', ' ', text)\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6XZ5kJFpPvj"
      },
      "outputs": [],
      "source": [
        "clean_lines = [clean_text(line) for line in tqdm(lines)]\n",
        "clean_lines"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "И присутпаем к созданию n-gram модели. Определим функцию, которая считает n-gramы"
      ],
      "metadata": {
        "id": "dAtZQcu6GpM7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2LAxCV-Iftde"
      },
      "outputs": [],
      "source": [
        "# special tokens:\n",
        "# - `UNK` represents absent tokens,\n",
        "# - `EOS` is a special token after the end of sequence\n",
        "\n",
        "UNK, EOS = \"_UNK_\", \"_EOS_\"\n",
        "\n",
        "def count_ngrams(lines, n):\n",
        "    \"\"\"\n",
        "    Подсчитывает, сколько раз каждое слово встречалось после (n - 1) предыдущих слов.\n",
        "\n",
        "    :param lines: итерируемый объект со строками пробельно-разделенных токенов\n",
        "    :returns: словарь { кортеж(токены_префикса): {следующий_токен_1: счетчик_1, следующий_токен_2: счетчик_2}}\n",
        "    \"\"\"\n",
        "\n",
        "    counts = defaultdict(Counter)\n",
        "    for line in tqdm(lines):\n",
        "        tokens = line.split() + [EOS]\n",
        "\n",
        "        for i in range(len(tokens)):\n",
        "            prefix = []\n",
        "\n",
        "            for j in range(n - 1):\n",
        "                pos = i - (n - 1) + j\n",
        "                if pos < 0:\n",
        "                    prefix.append(UNK)\n",
        "                else:\n",
        "                    prefix.append(tokens[pos])\n",
        "            prefix = tuple(prefix)\n",
        "\n",
        "            next_token = tokens[i]\n",
        "\n",
        "            counts[prefix][next_token] += 1\n",
        "\n",
        "    return counts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определим языковую n граммную модель со сглаживанием Лапласа. В данном случае нам крайне необходимо определить не классическую n граммную модель, а именно со сглаживанием, так как иначе незнакомые слова будут получать нулевые вероятности, что чревато потерей информации и неустойчивость модели к словам, отсутствующим в тренировочном корпусе"
      ],
      "metadata": {
        "id": "auPj3vnE0aSP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8L1tgRAmnK24"
      },
      "outputs": [],
      "source": [
        "class LaplaceLanguageModel:\n",
        "    def __init__(self, lines, n, delta=1.0, len_decay=0.3):\n",
        "        self.n = n\n",
        "        self.delta = delta\n",
        "        self.len_decay = len_decay\n",
        "\n",
        "        # считаем n-граммы и униграммы\n",
        "        self.uni = Counter()\n",
        "        for line in lines:\n",
        "            self.uni.update(line.strip().split())\n",
        "\n",
        "        counts = count_ngrams(lines, self.n)\n",
        "        self.vocab = set(t for d in counts.values() for t in d)\n",
        "        self.V = max(1, len(self.vocab))\n",
        "        self.total_uni = sum(self.uni.values()) + delta * (self.V + 1)\n",
        "\n",
        "        self.probs = defaultdict(dict)\n",
        "        for prefix, token_counts in counts.items():\n",
        "            total = sum(token_counts.values()) + delta * self.V\n",
        "            self.probs[prefix] = {t: (c + delta) / total for t, c in token_counts.items()}\n",
        "\n",
        "    def _norm_prefix(self, prefix):\n",
        "        p = prefix.split()[-(self.n-1):]\n",
        "        return tuple([UNK] * (self.n - 1 - len(p)) + p)\n",
        "\n",
        "    def get_possible_next_tokens(self, prefix):\n",
        "        return self.probs[self._norm_prefix(prefix)]\n",
        "\n",
        "    def get_next_token_prob(self, prefix, next_token):\n",
        "        seen = self.get_possible_next_tokens(prefix)\n",
        "        if next_token in seen:\n",
        "            return seen[next_token]\n",
        "\n",
        "        # backoff к униграммам, если слово вообще видели\n",
        "        if self.uni[next_token] > 0:\n",
        "            return (self.uni[next_token] + self.delta) / self.total_uni\n",
        "\n",
        "        # совсем неизвестное слово: сильный штраф по длине\n",
        "        L = max(1, len(next_token))\n",
        "        return (1.0 / (self.V + 1)) * (self.len_decay ** (L - 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4b98c401aa69453dba7a41076ca8cefd",
            "4470cca45cf44a03a0d6bb5a7b383089",
            "48080a74c881496bb89bf6b7fd087d7b",
            "e05138b362284fe8b6e8c9243a87f40b",
            "6205acef192e400bb5a6ee8bc95aa691",
            "ee21dfca4d07431ea47105ce714dfc71",
            "bd8f350cf3a0470c8034f5ec2d378375",
            "1fb10ce92ed2444cb1206fa4c1b4dfb6",
            "b8d60c0d22b94d98bc96a4a23cb45ce5",
            "a1c040cff33a47eca047e5e1bc86dda4",
            "3789550830e24e269fa53dc1d6f01c97"
          ]
        },
        "id": "wUVdpywthH0G",
        "outputId": "1139fd57-684a-46e8-bae4-f80002eb023d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/489517 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b98c401aa69453dba7a41076ca8cefd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "lm = LaplaceLanguageModel(lines, n=3, delta=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверяем работоспосбность модели"
      ],
      "metadata": {
        "id": "vyZ-PAhP0_NN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "CGsxF34GhQXo",
        "outputId": "0e01040b-db9a-4fb7-adc6-e4748de850a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ('моей', 'вашей', 'доплатой', 'разбитым', 'небольшой', 'документами,', 'новой', 'надписью', 'рабочем', 'доставкой', 'августа', 'док.', 'доплатой!', 'доплатой,', 'документами,не', 'доплатой.Комплект,коробка,документы,зарядное', 'небес') - probs: (1.9006921140939598e-05, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06, 1.9662332214765103e-06)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'надписью'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "possible_tokens = lm.get_possible_next_tokens('купить айфон с')\n",
        "\n",
        "tokens, probs = zip(*possible_tokens.items())\n",
        "print(f'Tokens: {tokens} - probs: {probs}')\n",
        "random.choices(tokens, k=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BOS = \"<s>\"\n",
        "UNK = \"<unk>\"\n",
        "\n",
        "def restore_spaces(text, language_model):\n",
        "    \"\"\"\n",
        "    Восстанавливает пробелы в тексте с помощью Viterbi и n-грамм LM.\n",
        "    language_model:\n",
        "        .n  -> порядок n-грамм\n",
        "        .get_next_token_prob(context_str, next_word_str) -> float in (0,1]\n",
        "    \"\"\"\n",
        "    n = language_model.n\n",
        "    L = len(text)\n",
        "    max_tok_len = 20\n",
        "\n",
        "    dp = [(-float(\"inf\"), -1) for _ in range(L + 1)]\n",
        "    dp[0] = (0.0, -1)\n",
        "\n",
        "    for i in range(1, L + 1):\n",
        "        j_start = max(0, i - max_tok_len)\n",
        "        for j in range(j_start, i):\n",
        "            prev_prob, _ = dp[j]\n",
        "            if prev_prob == -float(\"inf\"):\n",
        "                continue\n",
        "\n",
        "            word = text[j:i]\n",
        "\n",
        "            if j == 0:\n",
        "                context_words = [BOS] * (n - 1)\n",
        "            else:\n",
        "                context_words = []\n",
        "                pos = j\n",
        "                for _ in range(n - 1):\n",
        "                    if pos <= 0:\n",
        "                        context_words.append(BOS)\n",
        "                    else:\n",
        "                        prev_pos = dp[pos][1]\n",
        "                        if prev_pos < 0:\n",
        "                            context_words.append(BOS)\n",
        "                            pos = 0\n",
        "                        else:\n",
        "                            context_words.append(text[prev_pos:pos])\n",
        "                            pos = prev_pos\n",
        "                context_words.reverse()\n",
        "\n",
        "            context = \" \".join(context_words)\n",
        "\n",
        "            p = language_model.get_next_token_prob(context, word)\n",
        "            if p <= 0.0:\n",
        "                continue\n",
        "\n",
        "            total = prev_prob + math.log(p)\n",
        "            if total > dp[i][0]:\n",
        "                dp[i] = (total, j)\n",
        "\n",
        "    if dp[L][0] == -float(\"inf\"):\n",
        "        return text\n",
        "\n",
        "    parts = []\n",
        "    pos = L\n",
        "    while pos > 0:\n",
        "        _, prev_pos = dp[pos]\n",
        "        if prev_pos < 0:\n",
        "            parts.append(text[0:pos])\n",
        "            break\n",
        "        parts.append(text[prev_pos:pos])\n",
        "        pos = prev_pos\n",
        "\n",
        "    return \" \".join(reversed(parts)).strip()\n"
      ],
      "metadata": {
        "id": "jSI9YpH-xJ_m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(restore_spaces('работавМосквеудаленно', lm)) # проверяем работу алгоритма"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bVxSGGwSLu2",
        "outputId": "fe587b61-c178-489d-822a-c0a148f19b02"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "работа в Москве удаленно\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Читаем файл как один столбец\n",
        "df = pd.read_csv('dataset_1937770_3.txt', header=None, names=['data'], sep='SEP')\n",
        "\n",
        "# Разделяем данные на два столбца по первой запятой\n",
        "df[['part1', 'part2']] = df['data'].str.split(',', n=1, expand=True)\n",
        "\n",
        "# Удаляем исходный столбец\n",
        "df.drop(columns=['data'], inplace=True)\n",
        "\n",
        "# Из первой строки делаем header\n",
        "new_header = df.iloc[0]\n",
        "df = df[1:].set_axis(new_header, axis=1)\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "Z0xhsNtA9hhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines_no_spaces = df.apply(lambda row: row['text_no_spaces'], axis=1).tolist()\n",
        "lines_no_spaces"
      ],
      "metadata": {
        "id": "IQlXJSBp-MMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines_with_spaces = [restore_spaces(line, lm) for line in lines_no_spaces]\n",
        "lines_with_spaces # запускаем алгоритм"
      ],
      "metadata": {
        "id": "5vbSpRAN-20w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_space_positions(original, corrected):\n",
        "    \"\"\"\n",
        "    Находит позиции, куда нужно добавить пробелы в оригинальной строке,\n",
        "    чтобы получить исправленную строку.\n",
        "    :param original: Исходная строка без пробелов\n",
        "    :param corrected: Исправленная строка с пробелами\n",
        "    :returns: Список позиций (индексов) для добавления пробелов\n",
        "    \"\"\"\n",
        "    i, j = 0, 0\n",
        "    space_positions = []\n",
        "\n",
        "    while i < len(original) and j < len(corrected):\n",
        "        if original[i] == corrected[j]:\n",
        "            i += 1\n",
        "            j += 1\n",
        "        elif corrected[j] == ' ':\n",
        "            space_positions.append(i)\n",
        "            j += 1\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    while j < len(corrected) and corrected[j] == ' ':\n",
        "        space_positions.append(i)\n",
        "        j += 1\n",
        "\n",
        "    return space_positions\n"
      ],
      "metadata": {
        "id": "LU6EmRVGo7dp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_space_positions('куплюайфон14про','куплю айфон 14 про') # проверяем работоспособность"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpkjFZPqpkDX",
        "outputId": "48064234-8c98-40e6-a1ab-2e7792a8e1a0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 10, 12]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данном случае мы обучаем языковую модель на title + description, а значит n граммы не всегда похожи на запросы авито. Например, обычно пишут: \"куплю айфон 14\", \"ищу друга для общения\", \"сдам квартиру\" и так далее. У нас в датасете больше \"айфон 5\", \"картина\" и тд. Поэтому можно взять список разных ключевых слов, которые очень часто повторяются в запросах людей. А также просто привести строку к формату, где все будет по правилам русского языка: поставим пробел после знаков препинания (если нет пробела), перед открывающими скобками и после закрывающих, после чисел перед словами и так далее. Это должно сильно повысить f1 меру."
      ],
      "metadata": {
        "id": "bU99MqWxwSP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_missing_spaces(text):\n",
        "    \"\"\"\n",
        "    Добавляет пропущенные пробелы в текст в соответсвии с пунктуацией, сменой языков и регистром\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "\n",
        "    # Основные правила для добавления пробелов\n",
        "    patterns = [\n",
        "        # После знаков препинания (если нет пробела)\n",
        "        (r'([.,!?;:])([а-яА-Яa-zA-Z])', r'\\1 \\2'),\n",
        "        # Перед открывающими скобками и после закрывающих\n",
        "        (r'([а-яА-Яa-zA-Z])(\\()', r'\\1 \\2'),\n",
        "        (r'(\\))([а-яА-Яa-zA-Z])', r'\\1 \\2'),\n",
        "        # Вокруг тире (если оно используется как знак препинания)\n",
        "        (r'([а-яА-Яa-zA-Z])—([а-яА-Яa-zA-Z])', r'\\1 — \\2'),\n",
        "        # После чисел перед словами\n",
        "        (r'(\\d)([а-яА-Яa-zA-Z])', r'\\1 \\2'),\n",
        "        # Перед числами после слов\n",
        "        (r'([а-яА-Яa-zA-Z])(\\d)', r'\\1 \\2'),\n",
        "        # Перед заглавными буквами\n",
        "        (r'([а-яa-z])([А-ЯA-Z])', r'\\1 \\2'),\n",
        "        # При переходе с русского на английскйй\n",
        "        (r'([а-яА-Я])([A-Za-z])', r'\\1 \\2'),\n",
        "        # При переходе с английского на русский\n",
        "        (r'([A-Za-z])([а-яА-Я])', r'\\1 \\2'),\n",
        "    ]\n",
        "\n",
        "    result = str(text)\n",
        "\n",
        "    # Применяем все правила\n",
        "    for pattern, replacement in patterns:\n",
        "        result = re.sub(pattern, replacement, result)\n",
        "\n",
        "    # Убираем лишние пробелы\n",
        "    result = re.sub(r'\\s+', ' ', result).strip()\n",
        "\n",
        "    return result\n",
        "\n",
        "def add_spaces_by_keywords(text):\n",
        "    \"\"\"\n",
        "    Добавляет пропущенные пробелы в текст в соответсвии с наиболее логичными первыми словами в запросе\n",
        "\n",
        "    Тренировочный датасет содержал только тексты объявлений, поэтому слова, обозначающие намерение купить товар, проверяются отдельным словарем\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Слова, обозначающие намерение купить товар\n",
        "    patterns = [\"ищу\", \"куплю\", \"нужно\", \"хочу\"] #\n",
        "\n",
        "    # Добавление пробела после слов\n",
        "    pattern = '(' + '|'.join(patterns) + ')'\n",
        "    result = re.sub(pattern, r'\\1 ', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Убираем лишние пробелы\n",
        "    result = re.sub(r'\\s+', ' ', result).strip()\n",
        "\n",
        "    return result\n",
        "\n",
        "spaces_in_lines = [add_spaces_by_keywords(add_missing_spaces(line)) for line in lines_with_spaces]\n",
        "spaces_in_lines"
      ],
      "metadata": {
        "id": "E-kFygsQi5YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# составляем список из списков позиций пробела в строке\n",
        "# готовим файл к сдачи\n",
        "spaces_in_lines = [str(find_space_positions(lines_no_spaces[i], spaces_in_lines[i])) for i in range(len(lines_with_spaces))]\n",
        "spaces_in_lines"
      ],
      "metadata": {
        "id": "Nc1ATQ-CEMWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаем df и сохраняем файл\n",
        "submissions = pd.DataFrame({\n",
        "    'id': range(len(spaces_in_lines)),\n",
        "    'predicted_positions': spaces_in_lines\n",
        "})\n",
        "\n",
        "submissions.to_csv('submissions.csv', index=True, encoding='utf-8')"
      ],
      "metadata": {
        "id": "ND-FDKEPHvjI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submissions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2DyJc0fAi8Gt",
        "outputId": "d16a641c-61b1-4035-9068-9833bc6410b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id predicted_positions\n",
              "0        0                  []\n",
              "1        1                 [7]\n",
              "2        2            [20, 21]\n",
              "3        3         [5, 10, 18]\n",
              "4        4                  []\n",
              "...    ...                 ...\n",
              "1000  1000                  []\n",
              "1001  1001                  []\n",
              "1002  1002              [3, 5]\n",
              "1003  1003            [19, 22]\n",
              "1004  1004                  []\n",
              "\n",
              "[1005 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-689818ba-f765-4185-b7f0-f83b9f0989fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>predicted_positions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[20, 21]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[5, 10, 18]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>1000</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>1001</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>1002</td>\n",
              "      <td>[3, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>1003</td>\n",
              "      <td>[19, 22]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>1004</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1005 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-689818ba-f765-4185-b7f0-f83b9f0989fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-689818ba-f765-4185-b7f0-f83b9f0989fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-689818ba-f765-4185-b7f0-f83b9f0989fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-30db7f1b-926e-42fb-9a87-9c1539467e64\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-30db7f1b-926e-42fb-9a87-9c1539467e64')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-30db7f1b-926e-42fb-9a87-9c1539467e64 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submissions",
              "summary": "{\n  \"name\": \"submissions\",\n  \"rows\": 1005,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 290,\n        \"min\": 0,\n        \"max\": 1004,\n        \"num_unique_values\": 1005,\n        \"samples\": [\n          926,\n          630,\n          682\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_positions\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 210,\n        \"samples\": [\n          \"[5, 12]\",\n          \"[1, 3]\",\n          \"[7, 9, 11]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(submissions['predicted_positions'][0])"
      ],
      "metadata": {
        "id": "AJH3MHGCIWHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итог:\n",
        "\n",
        "*   LaplaceLM(n=3, delta=0.5) - F1 = 37%\n",
        "*   LaplaceLM(n=3, delta=0.5) + эвристика - F1 = 54% (примерно, как результат на степике)\n",
        "\n",
        "Первый реузльтат взят со степика, второй проверен на отдельном искусственном датасете (F1 на реальном датасете меньше на 1-2%, чем F1 на моем датасете).\n",
        "\n"
      ],
      "metadata": {
        "id": "sUQnWkDhr5X_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine-tuning BERT\n",
        "Задача восстановления пропущенных пробелов в тексте может быть сведена к задаче бинарной классификации на уровне символов: для каждой позиции между символами предсказывается наличие (1) или отсутствие (0) пробела.\n",
        "\n",
        "BERT идеально подходит для этой задачи, поскольку его архитектура позволяет эффективно анализировать контекстные зависимости между символами, а предобучение на больших текстовых корпусах обеспечивает хорошие начальные веса.\n",
        "\n",
        "# Данные\n",
        "Для обучения нам нужны данные. Воспользуемся уже знакомы датасетом avito-dataset. Из него я предлагаю взять только названия объявлений, так как они больше всего похожи на запросы пользователей, например, \"куплю айфон 14 про\". Чтобы дообучить BERT, нам надо исскуственно подогнать датасет под нас. Сделаем две колонки:\n",
        "\n",
        "*   Признак - текст без пробелов\n",
        "*   Таргет - текст с пробелами\n",
        "\n"
      ],
      "metadata": {
        "id": "rNPLLO9UrQhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titles = data.apply(lambda row: row['title'], axis=1).tolist()\n",
        "titles"
      ],
      "metadata": {
        "id": "xV4yPU8ZrQI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles_no_space = [title.replace(' ', '') for title in titles]\n",
        "titles_no_space"
      ],
      "metadata": {
        "id": "Jx8LVJs1xLD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrame = pd.DataFrame({\n",
        "    'input': titles_no_space,\n",
        "    'target': titles,\n",
        "})\n",
        "dataFrame"
      ],
      "metadata": {
        "id": "-nF59VUbxa_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь, когда у нас есть датасет, подготовим данные. Нам нужно воспользоваться функцией find_space_positions, которая вернет нам списки индексов, где должны стоять пробелы"
      ],
      "metadata": {
        "id": "lhCFUOCfY316"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(df):\n",
        "    \"\"\"Подготовка датасета для BERT\"\"\"\n",
        "    samples = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        text_with_spaces = row['target']  # строка с пробелами\n",
        "        text_without_spaces = row['input']  # строка без пробелов\n",
        "\n",
        "        text_with_spaces = re.sub(r'\\s+', ' ', text_with_spaces).strip()\n",
        "\n",
        "        space_positions = find_space_positions(text_without_spaces, text_with_spaces)\n",
        "\n",
        "        samples.append({\n",
        "            'text': text_without_spaces,\n",
        "            'labels': space_positions,\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(samples)\n",
        "prepare_dataset = prepare_dataset(dataFrame)\n",
        "print(prepare_dataset)"
      ],
      "metadata": {
        "id": "0T6qiCxIuEdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(prepare_dataset, test_size=0.1, random_state=42, shuffle=True) # разделим данные на train и test"
      ],
      "metadata": {
        "id": "oc_cYIwtx-DV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "E7hgc116w8No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определим класс SpaceDataset, чтобы  реализовать character-level classification, где:\n",
        "\n",
        "Каждый символ → отдельный токен\n",
        "\n",
        "Для каждого символа предсказываем: пробел после него или нет"
      ],
      "metadata": {
        "id": "D0LQyxQla72G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpaceDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        true_labels = self.labels[idx]\n",
        "\n",
        "        # Токенизация по символам\n",
        "        tokens = list(text)\n",
        "        inputs = self.tokenizer(\n",
        "            tokens,\n",
        "            is_split_into_words=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Создание масок и меток\n",
        "        label_ids = torch.zeros(self.max_length, dtype=torch.long)\n",
        "        attention_mask = torch.zeros(self.max_length, dtype=torch.long)\n",
        "\n",
        "        for i in range(min(len(tokens), self.max_length)):\n",
        "            attention_mask[i] = 1\n",
        "            if i in true_labels:\n",
        "                label_ids[i] = 1  # SPACE\n",
        "            else:\n",
        "                label_ids[i] = 0  # NO_SPACE\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': label_ids\n",
        "        }\n"
      ],
      "metadata": {
        "id": "H8iVFM_OxGIg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Цикл обучения\n",
        "Здесь мы определяем модель. Использовать будем \"cointegrated/rubert-tiny\", потому что она легкая и русскоязычная, как раз под нашу задачу.\n",
        "\n",
        "Обучение проводил два раза, на 3х эпохах и на 6, чтобы посмотреть на качество модели. Хотелось понять, будет ли качество лучше."
      ],
      "metadata": {
        "id": "ktIsOVXZjqsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
        "\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_name = 'cointegrated/rubert-tiny' # легкая русскоязычная модель\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,\n",
        "    id2label={0: \"NO_SPACE\", 1: \"SPACE\"},\n",
        "    label2id={\"NO_SPACE\": 0, \"SPACE\": 1}\n",
        ").to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Датасеты\n",
        "train_dataset = SpaceDataset(train['text'].tolist(),\n",
        "                            train['labels'].tolist(), tokenizer)\n",
        "val_dataset = SpaceDataset(test['text'].tolist(),\n",
        "                          test['labels'].tolist(), tokenizer)\n",
        "\n",
        "# Аргументы обучения\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    report_to=None,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=6,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "KoQLEejwxJT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_spaces(text_without_spaces, model, tokenizer, threshold=0.7):\n",
        "    \"\"\"Предсказание пробелов для нового текста\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    tokens = list(text_without_spaces)\n",
        "    inputs = tokenizer(\n",
        "        tokens,\n",
        "        is_split_into_words=True,\n",
        "        return_tensors='pt',\n",
        "        max_length=128,\n",
        "        padding=True,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probabilities = torch.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "    space_positions = []\n",
        "    for i in range(min(len(tokens), probabilities.shape[1])):\n",
        "        if probabilities[0, i, 1] > threshold:  # уверенность в пробеле\n",
        "            space_positions.append(i)\n",
        "\n",
        "    result = list(text_without_spaces)\n",
        "    for pos in sorted(space_positions, reverse=True):\n",
        "        if pos < len(result):\n",
        "            result.insert(pos, ' ')\n",
        "\n",
        "    return ''.join(result), space_positions\n",
        "\n",
        "def quick_test(model, tokenizer):\n",
        "    \"\"\n",
        "    test_cases = [\n",
        "        'куплюайфон14про',\n",
        "        'книгавхорошемсостоянии',\n",
        "        'стульяизпрессованнойкожи'\n",
        "    ]\n",
        "\n",
        "    for test_text in test_cases:\n",
        "        result, positions = predict_spaces(test_text, model, tokenizer)\n",
        "        print(f\"Вход:  {test_text}\")\n",
        "        print(f\"Выход: {result}\")\n",
        "        print(f\"Позиции: {positions}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "quick_test(model, tokenizer)"
      ],
      "metadata": {
        "id": "7ZEdkBrZyk7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "142a7c33-33d8-4bbe-da61-ec52189d484d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вход:  куплюайфон14про\n",
            "Выход: куплю айфон 14 про\n",
            "Позиции: [5, 10, 12]\n",
            "--------------------------------------------------\n",
            "Вход:  книгавхорошемсостоянии\n",
            "Выход: книга в хорошем состоянии\n",
            "Позиции: [5, 6, 13]\n",
            "--------------------------------------------------\n",
            "Вход:  стульяизпрессованнойкожи\n",
            "Выход: стулья из прессованной кожи\n",
            "Позиции: [6, 8, 20]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('dataset_1937770_3.txt', header=None, names=['data'], sep='SEP')\n",
        "df[['part1', 'part2']] = df['data'].str.split(',', n=1, expand=True)\n",
        "df.drop(columns=['data'], inplace=True)\n",
        "new_header = df.iloc[0]\n",
        "df = df[1:].set_axis(new_header, axis=1)\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "2ekeU7AdFds9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines_no_spaces = df.apply(lambda row: row['text_no_spaces'], axis=1).tolist()\n",
        "lines_no_spaces"
      ],
      "metadata": {
        "id": "EQfXAAQDFHea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spaces_in_lines = [predict_spaces(line, model, tokenizer)[0] for line in lines_no_spaces]\n",
        "spaces_in_lines # расставляем пробелы через BERT"
      ],
      "metadata": {
        "id": "95H0U-wuE99V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь, также как и в случае в LaplaceLM, решил попробовать улучшить f1 через эвристику. Добавил эти функции снова, чтобы не возвращаться в другие ячейки"
      ],
      "metadata": {
        "id": "6CQ0_0ohz9iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_missing_spaces(text):\n",
        "    \"\"\"\n",
        "    Добавляет пропущенные пробелы в текст в соответсвии с пунктуацией, сменой языков и регистром\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "\n",
        "    # Основные правила для добавления пробелов\n",
        "    patterns = [\n",
        "        # После знаков препинания (если нет пробела)\n",
        "        (r'([.,!?;:])([а-яА-Яa-zA-Z])', r'\\1 \\2'),\n",
        "        # Перед открывающими скобками и после закрывающих\n",
        "        (r'([а-яА-Яa-zA-Z])(\\()', r'\\1 \\2'),\n",
        "        (r'(\\))([а-яА-Яa-zA-Z])', r'\\1 \\2'),\n",
        "        # Вокруг тире (если оно используется как знак препинания)\n",
        "        (r'([а-яА-Яa-zA-Z])—([а-яА-Яa-zA-Z])', r'\\1 — \\2'),\n",
        "        # После чисел перед словами\n",
        "        (r'(\\d)([а-яА-Яa-zA-Z])', r'\\1 \\2'),\n",
        "        # Перед числами после слов\n",
        "        (r'([а-яА-Яa-zA-Z])(\\d)', r'\\1 \\2'),\n",
        "        # Перед заглавными буквами\n",
        "        (r'([а-яa-z])([А-ЯA-Z])', r'\\1 \\2'),\n",
        "        # При переходе с русского на английскйй\n",
        "        (r'([а-яА-Я])([A-Za-z])', r'\\1 \\2'),\n",
        "        # При переходе с английского на русский\n",
        "        (r'([A-Za-z])([а-яА-Я])', r'\\1 \\2'),\n",
        "    ]\n",
        "\n",
        "    result = str(text)\n",
        "\n",
        "    # Применяем все правила\n",
        "    for pattern, replacement in patterns:\n",
        "        result = re.sub(pattern, replacement, result)\n",
        "\n",
        "    # Убираем лишние пробелы\n",
        "    result = re.sub(r'\\s+', ' ', result).strip()\n",
        "\n",
        "    return result\n",
        "\n",
        "def add_spaces_by_keywords(text):\n",
        "    \"\"\"\n",
        "    Добавляет пропущенные пробелы в текст в соответсвии с наиболее логичными первыми словами в запросе\n",
        "\n",
        "    Тренировочный датасет содержал только тексты объявлений, поэтому слова, обозначающие намерение купить товар, проверяются отдельным словарем\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Слова, обозначающие намерение купить товар\n",
        "    patterns = [\"ищу\", \"куплю\", \"нужно\", \"хочу\"] #\n",
        "\n",
        "    # Добавление пробела после слов\n",
        "    pattern = '(' + '|'.join(patterns) + ')'\n",
        "    result = re.sub(pattern, r'\\1 ', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Убираем лишние пробелы\n",
        "    result = re.sub(r'\\s+', ' ', result).strip()\n",
        "\n",
        "    return result\n",
        "\n",
        "spaces_in_lines = [add_spaces_by_keywords(add_missing_spaces(line)) for line in spaces_in_lines]\n",
        "spaces_in_lines # получили список обработанных строк"
      ],
      "metadata": {
        "id": "K7QaCQSyc8et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = [str(find_space_positions(line.replace(' ', ''), line)) for line in spaces_in_lines]\n",
        "result # получаем позиции пробелов в строках"
      ],
      "metadata": {
        "id": "EZgsLMlEhHnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаем файл и сохраняем результаты\n",
        "submissions = pd.DataFrame({\n",
        "    'id': range(len(spaces_in_lines)),\n",
        "    'predicted_positions': result\n",
        "})\n",
        "\n",
        "submissions.to_csv('submissions.csv', index=True, encoding='utf-8')"
      ],
      "metadata": {
        "id": "Lstwdi8KE4Qd"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итог:\n",
        "\n",
        "*   3 эпохи - F1 = 71%\n",
        "*   6 эпох - F1 = 76%\n",
        "*   BERT (6 эпох) + эвристика - F1 = 79%\n",
        "\n",
        "Результаты брал с степика.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Sn-fIPt1H3t8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вывод\n",
        "Если сравнивать два способа, то очевидно, что BERT по качеству побеждает, причем сильно (79 - 34 = 45% разница). Но стоит понимать, что BERT использует сильно больше вычислительных ресурсов, из-за чего не всегда оно того стоит. Тем более, что эвристика + LaplaceLM уже сокращает разницу (79 - 54 = 25%).\n",
        "\n",
        "Поэтому тут появляется выбор:\n",
        "\n",
        "\n",
        "*   Потерять в качестве, но выиграть в ресурсах - LaplaceLM\n",
        "*   Потерять в ресурсах, но выиграть в качестве - BERT\n",
        "\n",
        "Также стоит отметить, что в датасете были не только объявления с авито, а еще и текста разных песен, из-за чего мои модели выдавали качество меньше, чем могло быть на реальных кейсах с авито. Это произошло из-за того, что я обучал их на специфичном датасете, связанном конкретно с Авито.\n",
        "Без строчек песен я получил результаты:\n",
        "\n",
        "\n",
        "*   LaplaceLM - F1 = 77%\n",
        "*   BERT - F1 = 92%\n",
        "\n"
      ],
      "metadata": {
        "id": "gms_Ebx40a5P"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b98c401aa69453dba7a41076ca8cefd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4470cca45cf44a03a0d6bb5a7b383089",
              "IPY_MODEL_48080a74c881496bb89bf6b7fd087d7b",
              "IPY_MODEL_e05138b362284fe8b6e8c9243a87f40b"
            ],
            "layout": "IPY_MODEL_6205acef192e400bb5a6ee8bc95aa691"
          }
        },
        "4470cca45cf44a03a0d6bb5a7b383089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee21dfca4d07431ea47105ce714dfc71",
            "placeholder": "​",
            "style": "IPY_MODEL_bd8f350cf3a0470c8034f5ec2d378375",
            "value": "100%"
          }
        },
        "48080a74c881496bb89bf6b7fd087d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fb10ce92ed2444cb1206fa4c1b4dfb6",
            "max": 489517,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8d60c0d22b94d98bc96a4a23cb45ce5",
            "value": 489517
          }
        },
        "e05138b362284fe8b6e8c9243a87f40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1c040cff33a47eca047e5e1bc86dda4",
            "placeholder": "​",
            "style": "IPY_MODEL_3789550830e24e269fa53dc1d6f01c97",
            "value": " 489517/489517 [01:10&lt;00:00, 10009.88it/s]"
          }
        },
        "6205acef192e400bb5a6ee8bc95aa691": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee21dfca4d07431ea47105ce714dfc71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd8f350cf3a0470c8034f5ec2d378375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fb10ce92ed2444cb1206fa4c1b4dfb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8d60c0d22b94d98bc96a4a23cb45ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1c040cff33a47eca047e5e1bc86dda4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3789550830e24e269fa53dc1d6f01c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}